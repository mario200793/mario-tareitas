{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0o9ATjE2B_N"
   },
   "source": [
    "# Clasificación de imágenes entre perros y gatos\n",
    "### Nota:\n",
    "Instalar conda install pillow y reiniciar ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtqAiI3i2B_O"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tca8XR_8GtuD",
    "outputId": "c271173e-bfd4-466c-e3e7-e6beb4f2a593"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1f8wKOP2B_P"
   },
   "source": [
    "### Crear carpetas de entrenamiento, prueba y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVysTyuE2B_x"
   },
   "outputs": [],
   "source": [
    "#Para volver a correr el código no es necesario crear y asignar las carpetas y las imágenes de nuevo.\n",
    "#Directorio local\n",
    "base_dir = '/home/aulae1//Curso_ML/cats_and_dogs_short/cats_and_dogs_short'\n",
    "#Directorio en drive\n",
    "#base_dir = '/content/drive/My Drive/cats_and_dogs_small_ndsl'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "#directorios de gatos\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "#directorios de perros\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "50sfdDJG5t60",
    "outputId": "f3baedf1-8080-4c8e-df6d-68fb65aa9642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aulae1//Curso_ML/cats_and_dogs_short/cats_and_dogs_short/validation/dogs\n",
      "/home/aulae1//Curso_ML/cats_and_dogs_short/cats_and_dogs_short/train\n"
     ]
    }
   ],
   "source": [
    "print(validation_dogs_dir)\n",
    "print(train_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGzGbm2u2B_y"
   },
   "source": [
    "# Construir la red convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVwpDj202B_y"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QUuhTmE2B_z"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDzOelv12B_1"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3))) # **\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())#*\n",
    "model.add(layers.Dense(512, activation='relu'))#cantidad de datos propuestos para la capa\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "YabDT33H2B_2",
    "outputId": "74118f05-9edd-4a4c-adfc-bb99b427036f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tt6p8BrE2B_2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIPGRzYh2B_3"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06qhqkWZ2B_4"
   },
   "source": [
    "# Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JgbBE8A2B_5"
   },
   "source": [
    "1. Leer imágenes\n",
    "2. Decodificar JPG a matriz RGB de pixeles\n",
    "3. Convertir puntos flotantes en tensores\n",
    "4. Escalar pixeles valores[0,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsfD1Dkr2B_5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kkj0TMwD2B_5"
   },
   "source": [
    "ImageDataGenerator convierne automaticamente imágenes en tensores preprocesados\n",
    "\n",
    "#### Generador en python\n",
    "Un generador es un objeto que actua como un iterador, usan el operador \"yield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbGR-6td2B_6"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255) #todos los pixeles estarán entre 0 y 255\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "Ekdchg-82B_7",
    "outputId": "33d2a35c-3c35-4fac-edfd-eaf784efb92d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150), #Rescala las imagenes a 150x150\n",
    "    batch_size=20,\n",
    "    class_mode='binary') #Solo dos clases (perro,gato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZXE9V1mO2B_7",
    "outputId": "3820ffc3-cf83-42f1-a15b-fd54905dd49c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-VrW4G6c2B_9",
    "outputId": "c9558bac-f4d7-4b6f-b558-86b45fe17ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqHnOulx2B_-"
   },
   "source": [
    "fit_generator es equivalente a fit, como argumento espera un objeto del tipo generador que arroja bloques de las imágenes de entrada.\n",
    "Es necesario especificar el número de pasos por época, recordemos que tenemos 2000 datos de entrenamiento y el objeto Generador toma bloque de 20, entonces 20*100 = 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8xnJCk7E2B_-",
    "outputId": "890f1414-5de1-4f29-8586-9281ab0db206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-e212732177d6>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.6824 - accuracy: 0.5615 - val_loss: 0.6661 - val_accuracy: 0.6210\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.6463 - accuracy: 0.6305 - val_loss: 0.6313 - val_accuracy: 0.6300\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.5915 - accuracy: 0.6985 - val_loss: 0.6517 - val_accuracy: 0.6310\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.5583 - accuracy: 0.7150 - val_loss: 0.5882 - val_accuracy: 0.6830\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.5248 - accuracy: 0.7390 - val_loss: 0.5932 - val_accuracy: 0.6800\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.4997 - accuracy: 0.7580 - val_loss: 0.6080 - val_accuracy: 0.6840\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.4736 - accuracy: 0.7715 - val_loss: 0.5550 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.4477 - accuracy: 0.7935 - val_loss: 0.5672 - val_accuracy: 0.7060\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.4168 - accuracy: 0.8155 - val_loss: 0.5583 - val_accuracy: 0.7160\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.3841 - accuracy: 0.8245 - val_loss: 0.5547 - val_accuracy: 0.7190\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.3626 - accuracy: 0.8410 - val_loss: 0.5416 - val_accuracy: 0.7290\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 0.3382 - accuracy: 0.8595 - val_loss: 0.5714 - val_accuracy: 0.7140\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 0.3177 - accuracy: 0.8625 - val_loss: 0.5728 - val_accuracy: 0.7170\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.2837 - accuracy: 0.8810 - val_loss: 0.5948 - val_accuracy: 0.7260\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.2682 - accuracy: 0.8915 - val_loss: 0.6163 - val_accuracy: 0.7300\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.2365 - accuracy: 0.9100 - val_loss: 0.6255 - val_accuracy: 0.7240\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.2225 - accuracy: 0.9180 - val_loss: 0.6295 - val_accuracy: 0.7180\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.2006 - accuracy: 0.9300 - val_loss: 0.6616 - val_accuracy: 0.7270\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.1827 - accuracy: 0.9330 - val_loss: 0.7197 - val_accuracy: 0.7250\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.1639 - accuracy: 0.9405 - val_loss: 0.7139 - val_accuracy: 0.7260\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.1500 - accuracy: 0.9460 - val_loss: 0.7749 - val_accuracy: 0.7120\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.1270 - accuracy: 0.9585 - val_loss: 0.7544 - val_accuracy: 0.7400\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.1084 - accuracy: 0.9635 - val_loss: 0.7441 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 0.0945 - accuracy: 0.9705 - val_loss: 0.7797 - val_accuracy: 0.7430\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.7936 - val_accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 0.0694 - accuracy: 0.9800 - val_loss: 1.0329 - val_accuracy: 0.6960\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 0.0590 - accuracy: 0.9835 - val_loss: 1.1399 - val_accuracy: 0.7150\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.9510 - val_accuracy: 0.7340\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 0.0399 - accuracy: 0.9910 - val_loss: 1.0263 - val_accuracy: 0.7410\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.0416 - accuracy: 0.9900 - val_loss: 0.9793 - val_accuracy: 0.7380\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 0.0323 - accuracy: 0.9935 - val_loss: 1.0807 - val_accuracy: 0.7290\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 1.0771 - val_accuracy: 0.7350\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 1.1234 - val_accuracy: 0.7360\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 1.2506 - val_accuracy: 0.7280\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.1779 - val_accuracy: 0.7300\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 1.2417 - val_accuracy: 0.7250\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.0159 - accuracy: 0.9980 - val_loss: 1.3986 - val_accuracy: 0.7190\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 1.3277 - val_accuracy: 0.7420\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.0159 - accuracy: 0.9935 - val_loss: 1.3200 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 1.3763 - val_accuracy: 0.7330\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 1.4017 - val_accuracy: 0.7450\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 1.4764 - val_accuracy: 0.7390\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 1.5342 - val_accuracy: 0.7340\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0154 - accuracy: 0.9965 - val_loss: 1.6424 - val_accuracy: 0.7330\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 1.4684 - val_accuracy: 0.7430\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 1.5425 - val_accuracy: 0.7450\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 1.6959 - val_accuracy: 0.7290\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.0067 - accuracy: 0.9970 - val_loss: 1.6369 - val_accuracy: 0.7390\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 1.7603 - val_accuracy: 0.7420\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 1.6930 - val_accuracy: 0.7460\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 1.7898 - val_accuracy: 0.7450\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.7892 - val_accuracy: 0.7450\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 1.7339 - val_accuracy: 0.7410\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.9408 - val_accuracy: 0.7230\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 1.9909 - val_accuracy: 0.7310\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0409 - val_accuracy: 0.7250\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 1.9053 - val_accuracy: 0.7480\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 1.8447 - val_accuracy: 0.7490\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 1.9737 - val_accuracy: 0.7430\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.9154 - val_accuracy: 0.7490\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 2.0337 - val_accuracy: 0.7410\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 2.6292 - val_accuracy: 0.6830\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 0.0057 - accuracy: 0.9975 - val_loss: 2.0711 - val_accuracy: 0.7310\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.0943 - val_accuracy: 0.7400\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 2.1198 - val_accuracy: 0.7120\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 2.2940 - val_accuracy: 0.7190\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 2.0561 - val_accuracy: 0.7400\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 2.1431 - val_accuracy: 0.7450\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 3.1711e-04 - accuracy: 1.0000 - val_loss: 2.1251 - val_accuracy: 0.7520\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.1735 - val_accuracy: 0.7430\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 2.1843 - val_accuracy: 0.7470\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.0068 - accuracy: 0.9970 - val_loss: 2.9225 - val_accuracy: 0.7180\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.2824 - val_accuracy: 0.7430\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 2.2757 - val_accuracy: 0.7330\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 3.5034e-04 - accuracy: 1.0000 - val_loss: 2.3962 - val_accuracy: 0.7420\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 2.2457 - val_accuracy: 0.7430\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 0.0029 - accuracy: 0.9985 - val_loss: 2.3296 - val_accuracy: 0.7360\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 2.4290 - val_accuracy: 0.7340\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 2.3496 - val_accuracy: 0.7430\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 2.5654 - val_accuracy: 0.7310\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 2.5335 - val_accuracy: 0.7420\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 2.6967 - val_accuracy: 0.7380\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 2.4821 - val_accuracy: 0.7380\n",
      "Epoch 84/100\n",
      "  3/100 [..............................] - ETA: 27s - loss: 1.0534e-04 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100,# Epocas\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIrSWtNl2B__"
   },
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_01.h5') #Salvar el modelo después del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aU57FL6U2CAA"
   },
   "source": [
    "# Imprimir curvas de precisión y pérdida durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQkofZc02CAA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Zrz33Hp2CAB"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgfM-lrZ2CAC"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zC6axMMi2CAD",
    "outputId": "28469789-d0fb-4376-eba2-44cde9a45179"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aq43vux22CAE"
   },
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qlMTckz52CAE"
   },
   "source": [
    "Las gráficas anteriores muestran que el modelo sufre de sobreajuste, debido a la baja cantidad de datos el modelo no es capaz de generalizar. Data augmenting es generar de forma artificial mas datos de entrenamiento de los datos existentes por medio de transformaciones aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unxCTR8O2CAE"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oF6uf2k22CAF"
   },
   "source": [
    "Propiedades de este generador pueden ser consultadas en: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "- *rotation_range* es un valor en grados (0-180)\n",
    "- *width_shift* y *height_shift* son rangos de los cuáles una imagen se puede trasladar vertical u horizontalmente\n",
    "- *shear_range* aplicar de forma aleatoria cortes\n",
    "- *zoom_range* aleatoriamente aplicar zoom\n",
    "- *horizontal_flip*  voltear la imagen horizontalmente(importante cuando no se asume simetría horizonal)\n",
    "- *fill_mode* llenar los pixeles nuevos que fueron creados en las transformaciones anteriores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWXzrbS72CAF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLTxiOJ62CAH"
   },
   "outputs": [],
   "source": [
    "fnames = [os.path.join(train_cats_dir, fname) for\n",
    "fname in os.listdir(train_cats_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edjLZN842CAH"
   },
   "outputs": [],
   "source": [
    "img_path = fnames[99] # Se elige una imagen a aumentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZxG7Ld82CAI"
   },
   "outputs": [],
   "source": [
    "img = image.load_img(img_path, target_size=(150, 150)) # lee la imagen y se ajusta al tamaño 150x150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZK1AgtI2CAK"
   },
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXCf-Lrh2CAL",
    "outputId": "eab134f6-bd56-40e8-8145-eb9a316037bb"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai7Yv1YW2CAM"
   },
   "source": [
    "# Crear una nueva convnet con dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbEUHYst2CAM"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1iTYFoc2CAN"
   },
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laSrLy_w2CAP"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZSEBAB62CAT"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZc4hlwl2CAU"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOjbEFAn2CAU",
    "outputId": "c568ba66-aaea-404c-f726-e10acdf1ed9f"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yrf5iL4l2CAW",
    "outputId": "063ef470-c39d-4730-b06b-af793de38d28"
   },
   "outputs": [],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZOM5OO82CAX",
    "outputId": "20b1a4f6-43a1-47b2-a996-9f6fa93a8919"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1j1vBlE92CAY"
   },
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dSKDE6-2CAZ"
   },
   "outputs": [],
   "source": [
    "acc1 = history.history['accuracy']\n",
    "val_acc1 = history.history['val_accuracy']\n",
    "loss1 = history.history['loss']\n",
    "val_loss1 = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5ezamUB2CAe"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(acc1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6MlKXV12CAf",
    "outputId": "2979cbca-b89b-4dc4-a8a5-72022788e224"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc1, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc1, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss1, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss1, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2fpAya42CAy"
   },
   "outputs": [],
   "source": [
    "dog_imag_path = '/Users/edgarromo/anaconda3/envs/curso_ML19/practica_deep/cats_and_dogs_short/test/dogs/dog.1512.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cQQ6XqudSj6"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_uls9i32CAy"
   },
   "outputs": [],
   "source": [
    "img = image.load_img(dog_imag_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZfE3IL22CAz",
    "outputId": "25205a47-303a-4729-e6a3-99a1239bf11a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tymx20_2CA0"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bolrsBFM2CA0",
    "outputId": "2380699d-37fd-43b4-d691-fa30150d3fd4"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iptEWRkb2CA1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz-zmJUcdUgX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDi9UohOfV8u"
   },
   "outputs": [],
   "source": [
    "#model = load_model('/content/drive/My Drive/cats_and_dogs_small_2.h5')  # para el caso de drive\n",
    "model = load_model('/Users/edgarromo/anaconda3/envs/curso_ML19/practica_deep/1cats_and_dogs_small_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "R1KI-N8dfqlJ",
    "outputId": "aec4f6c8-fca8-46f3-f887-198ea26a7cc2"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72E2Ljjjf7jB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6dQtPWTf_MP"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ASqLJiMbgA-k",
    "outputId": "db407542-2511-4e73-ebe2-c018f30034b6"
   },
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b-KbWJQ4g14y",
    "outputId": "8644b8bc-56d2-493a-af13-f373e1ef344f"
   },
   "outputs": [],
   "source": [
    " model.evaluate_generator(test_generator, steps=100,\n",
    "                   callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aU57FL6U2CAA",
    "aq43vux22CAE",
    "Ai7Yv1YW2CAM"
   ],
   "name": "Copia de ConvsCat&Dog.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
